{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manisharout/My_Projects/blob/main/VeloCity_Insights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "a360a844",
        "outputId": "cb2aacf5-9131-4f33-b863-963dc990994b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95d4eba9-8288-417b-a1ea-0d657a9dae24\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95d4eba9-8288-417b-a1ea-0d657a9dae24\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving weatherHistory.csv to weatherHistory.csv\n",
            "Saving city_day.csv to city_day.csv\n",
            "Saving Metro_Interstate_Traffic_Volume.csv to Metro_Interstate_Traffic_Volume.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07781385",
        "outputId": "a2f0b755-18e0-41cb-e7aa-da18110b4583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dash\n",
            "  Downloading dash-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting dash-core-components\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-html-components\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: Flask<3.2,>=1.0.4 in /usr/local/lib/python3.12/dist-packages (from dash) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug<3.2 in /usr/local/lib/python3.12/dist-packages (from dash) (3.1.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/dist-packages (from dash) (8.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from dash) (4.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from dash) (2.32.4)\n",
            "Collecting retrying (from dash)\n",
            "  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from dash) (75.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<3.2,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from Flask<3.2,>=1.0.4->dash) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<3.2,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<3.2,>=1.0.4->dash) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<3.2,>=1.0.4->dash) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata->dash) (3.23.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->dash) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->dash) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->dash) (2025.8.3)\n",
            "Downloading dash-3.2.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: dash-html-components, dash-core-components, retrying, dash\n",
            "Successfully installed dash-3.2.0 dash-core-components-2.0.0 dash-html-components-2.0.0 retrying-1.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install dash dash-core-components dash-html-components plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "50332039",
        "outputId": "bef08c64-2eec-4c68-efbe-1b8f41f970de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame 'merged' not available or empty. Cannot define Dash app.\n"
          ]
        }
      ],
      "source": [
        "import dash\n",
        "from dash import dcc\n",
        "from dash import html\n",
        "from dash.dependencies import Input, Output\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "if 'merged' in globals() and merged is not None and not merged.empty:\n",
        "    df = merged.copy()\n",
        "\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df['date_time']):\n",
        "        try:\n",
        "            df['date_time'] = pd.to_datetime(df['date_time'])\n",
        "            if df['date_time'].dt.tz:\n",
        "                 df['date_time'] = df['date_time'].dt.tz_convert(None)\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting date_time to datetime: {e}\")\n",
        "            df = None\n",
        "\n",
        "\n",
        "    if df is not None:\n",
        "        app = dash.Dash(__name__)\n",
        "\n",
        "        app.layout = html.Div([\n",
        "            html.H1(\"Traffic Volume and PM2.5 Analysis Dashboard\"),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Time Series Analysis\"),\n",
        "                dcc.Graph(id='time-series-traffic'),\n",
        "                dcc.Graph(id='time-series-pm25')\n",
        "            ]),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Scatter Plot: Traffic Volume vs. Temperature\"),\n",
        "                dcc.Graph(id='scatter-traffic-temp')\n",
        "            ]),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Distribution Analysis\"),\n",
        "                dcc.Graph(id='hist-traffic'),\n",
        "                dcc.Graph(id='hist-pm25')\n",
        "            ]),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Weather Condition Analysis\"),\n",
        "                dcc.Graph(id='bar-weather-traffic')\n",
        "            ]),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Date Range Slider\"),\n",
        "                dcc.RangeSlider(\n",
        "                    id='date-range-slider',\n",
        "                    min=0,\n",
        "                    max=len(df['date_time']) - 1,\n",
        "                    value=[0, len(df['date_time']) - 1],\n",
        "                    marks={i: df['date_time'].iloc[i].strftime('%Y-%m-%d') for i in range(0, len(df['date_time']), len(df) // 5)}, # Example marks\n",
        "                    step=1\n",
        "                )\n",
        "            ])\n",
        "        ])\n",
        "\n",
        "        @app.callback(\n",
        "            [Output('time-series-traffic', 'figure'),\n",
        "             Output('time-series-pm25', 'figure'),\n",
        "             Output('scatter-traffic-temp', 'figure'),\n",
        "             Output('hist-traffic', 'figure'),\n",
        "             Output('hist-pm25', 'figure'),\n",
        "             Output('bar-weather-traffic', 'figure')],\n",
        "            [Input('date-range-slider', 'value')]\n",
        "        )\n",
        "        def update_graphs(date_range):\n",
        "            if df is None:\n",
        "                return {}, {}, {}, {}, {}, {} # Return empty figures if df is None\n",
        "\n",
        "            start_index, end_index = date_range\n",
        "            filtered_df = df.iloc[start_index:end_index+1]\n",
        "\n",
        "            # Time Series Traffic\n",
        "            fig_traffic_ts = px.line(filtered_df, x='date_time', y='traffic_volume', title='Traffic Volume Over Time')\n",
        "\n",
        "            # Time Series PM2.5\n",
        "            fig_pm25_ts = px.line(filtered_df, x='date_time', y='PM2.5', title='PM2.5 Levels Over Time')\n",
        "\n",
        "            # Scatter Traffic vs Temp\n",
        "            fig_scatter_temp = px.scatter(filtered_df, x='temp', y='traffic_volume', title='Traffic Volume vs. Temperature')\n",
        "\n",
        "            # Histogram Traffic\n",
        "            fig_hist_traffic = px.histogram(filtered_df, x='traffic_volume', title='Distribution of Traffic Volume')\n",
        "\n",
        "            # Histogram PM2.5\n",
        "            fig_hist_pm25 = px.histogram(filtered_df, x='PM2.5', title='Distribution of PM2.5 Levels')\n",
        "\n",
        "            # Bar Weather vs Traffic\n",
        "            if 'weather_main' in filtered_df.columns:\n",
        "                weather_traffic = filtered_df.groupby('weather_main')['traffic_volume'].mean().reset_index()\n",
        "                fig_bar_weather_traffic = px.bar(weather_traffic, x='weather_main', y='traffic_volume', title='Average Traffic Volume by Weather Condition')\n",
        "            else:\n",
        "                fig_bar_weather_traffic = {}\n",
        "\n",
        "\n",
        "            return fig_traffic_ts, fig_pm25_ts, fig_scatter_temp, fig_hist_traffic, fig_hist_pm25, fig_bar_weather_traffic\n",
        "\n",
        "        print(\"Dash app defined. To run the app in Colab, you can use:\")\n",
        "        print(\"from google.colab.output import eval_js\")\n",
        "        print(\"print(eval_js(app.run_server(mode='external')))\")\n",
        "\n",
        "    else:\n",
        "        print(\"DataFrame 'merged' not available or empty. Cannot define Dash app.\")\n",
        "\n",
        "else:\n",
        "    print(\"DataFrame 'merged' not available or empty. Cannot define Dash app.\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7c623986",
        "outputId": "aa6da165-d861-42e0-f182-a22da3719e83"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "merged = None\n",
        "model_tuned_classification = None\n",
        "model_tuned_regression = None\n",
        "X_train_classification = None\n",
        "X_test_classification = None\n",
        "y_train_classification = None\n",
        "y_test_classification = None\n",
        "X_train_regression = None\n",
        "X_test_regression = None\n",
        "y_train_regression = None\n",
        "y_test_regression = None\n",
        "\n",
        "traffic_filename = \"Metro_Interstate_Traffic_Volume.csv\"\n",
        "air_quality_filename = \"city_day.csv\"\n",
        "weather_filename = \"weatherHistory.csv\"\n",
        "\n",
        "try:\n",
        "    print(\"--- Starting Data Loading ---\")\n",
        "    if os.path.exists(traffic_filename) and os.path.exists(air_quality_filename) and os.path.exists(weather_filename):\n",
        "        try:\n",
        "            traffic = pd.read_csv(traffic_filename)\n",
        "            air_quality = pd.read_csv(air_quality_filename)\n",
        "            weather = pd.read_csv(weather_filename)\n",
        "            print(\"All CSV files loaded successfully.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading CSV files: {e}\")\n",
        "            traffic, air_quality, weather = None, None, None\n",
        "    else:\n",
        "        print(\"Error: One or more CSV files not found in the expected location after upload.\")\n",
        "        traffic, air_quality, weather = None, None, None\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during data loading: {e}\")\n",
        "    traffic, air_quality, weather = None, None, None\n",
        "\n",
        "if traffic is not None and air_quality is not None and weather is not None:\n",
        "    try:\n",
        "        print(\"\\nStarting data cleaning and imputation...\")\n",
        "\n",
        "        print(\"\\nMissing values before imputation:\")\n",
        "        print(\"Traffic:\\n\", traffic.isnull().sum())\n",
        "        print(\"\\nAir Quality:\\n\", air_quality.isnull().sum())\n",
        "        print(\"\\nWeather:\\n\", weather.isnull().sum())\n",
        "\n",
        "        try:\n",
        "            if 'date_time' in traffic.columns:\n",
        "                traffic['date_time'] = pd.to_datetime(traffic['date_time'])\n",
        "                if traffic['date_time'].dt.tz:\n",
        "                    traffic['date_time'] = traffic['date_time'].dt.tz_convert(None)\n",
        "                print(\"Processed traffic 'date_time' column.\")\n",
        "            else:\n",
        "                 print(\"Warning: 'date_time' column not found in traffic DataFrame.\")\n",
        "\n",
        "\n",
        "            if 'Date' in air_quality.columns:\n",
        "                air_quality['Date'] = pd.to_datetime(air_quality['Date'])\n",
        "                if air_quality['Date'].dt.tz:\n",
        "                    air_quality['Date'] = air_quality['Date'].dt.tz_convert(None)\n",
        "                print(\"Processed air_quality 'Date' column.\")\n",
        "            else:\n",
        "                 print(\"Warning: 'Date' column not found in air_quality DataFrame.\")\n",
        "\n",
        "\n",
        "            if 'Formatted Date' in weather.columns:\n",
        "                 weather['Formatted Date'] = pd.to_datetime(weather['Formatted Date'], utc=True).dt.tz_convert(None)\n",
        "                 print(\"Processed weather 'Formatted Date' column.\")\n",
        "            else:\n",
        "                 print(\"Warning: 'Formatted Date' column not found in weather DataFrame.\")\n",
        "\n",
        "\n",
        "        except (ValueError, TypeError) as e:\n",
        "            print(f\"Error converting date columns: {e}\")\n",
        "\n",
        "        for col in traffic.select_dtypes(include=['float64', 'int64']).columns:\n",
        "            if traffic[col].isnull().any():\n",
        "                mean_val = traffic[col].mean()\n",
        "                traffic[col] = traffic[col].fillna(mean_val)\n",
        "\n",
        "        for col in traffic.select_dtypes(include=['object']).columns:\n",
        "            if traffic[col].isnull().any():\n",
        "                mode_val = traffic[col].mode()[0]\n",
        "                traffic[col] = traffic[col].fillna(mode_val)\n",
        "        print(\"Traffic data imputed.\")\n",
        "\n",
        "        for col in air_quality.select_dtypes(include=['float64', 'int64']).columns:\n",
        "            if col != 'PM2.5' and air_quality[col].isnull().any():\n",
        "                mean_val = air_quality[col].mean()\n",
        "                air_quality[col] = air_quality[col].fillna(mean_val)\n",
        "\n",
        "        for col in air_quality.select_dtypes(include=['object']).columns:\n",
        "            if air_quality[col].isnull().any():\n",
        "                mode_val = air_quality[col].mode()[0]\n",
        "                air_quality[col] = air_quality[col].fillna(mode_val)\n",
        "        print(\"Air quality data (excluding PM2.5) imputed.\")\n",
        "\n",
        "        if 'PM2.5' in air_quality.columns and air_quality['PM2.5'].isnull().any():\n",
        "            air_quality.sort_values(by='Date', inplace=True)\n",
        "            air_quality['PM2.5'] = air_quality['PM2.5'].interpolate(method='linear').ffill().bfill() # Add ffill/bfill for edge cases\n",
        "            print(\"PM2.5 imputed using linear interpolation.\")\n",
        "        elif 'PM2.5' in air_quality.columns:\n",
        "            print(\"No missing values in PM2.5.\")\n",
        "        else:\n",
        "            print(\"Warning: 'PM2.5' column not found in air_quality DataFrame.\")\n",
        "\n",
        "        for col in weather.select_dtypes(include=['float64', 'int64']).columns:\n",
        "            if weather[col].isnull().any():\n",
        "                mean_val = weather[col].mean()\n",
        "                weather[col] = weather[col].fillna(mean_val)\n",
        "\n",
        "        for col in weather.select_dtypes(include=['object']).columns:\n",
        "            if weather[col].isnull().any():\n",
        "                mode_val = weather[col].mode()[0]\n",
        "                weather[col] = weather[col].fillna(mode_val)\n",
        "        print(\"Weather data imputed.\")\n",
        "\n",
        "        print(\"\\nMissing values after imputation:\")\n",
        "        print(\"Traffic:\\n\", traffic.isnull().sum())\n",
        "        print(\"\\nAir Quality:\\n\", air_quality.isnull().sum())\n",
        "        print(\"\\nWeather:\\n\", weather.isnull().sum())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during data cleaning and imputation: {e}\")\n",
        "        traffic, air_quality, weather = None, None, None\n",
        "\n",
        "if traffic is not None and air_quality is not None and weather is not None:\n",
        "    try:\n",
        "        print(\"\\n--- Starting Feature Engineering and Data Preparation ---\")\n",
        "\n",
        "        if 'date_time' not in traffic.columns:\n",
        "            raise ValueError(\"Traffic DataFrame is missing 'date_time' column for merging.\")\n",
        "        if 'Date' not in air_quality.columns:\n",
        "             raise ValueError(\"Air Quality DataFrame is missing 'Date' column for merging.\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            merged = pd.merge_asof(traffic.sort_values('date_time'),\n",
        "                                   air_quality.sort_values('Date'),\n",
        "                                   left_on='date_time',\n",
        "                                   right_on='Date')\n",
        "            print(\"Traffic and Air Quality DataFrames merged successfully.\")\n",
        "\n",
        "            merged = merged.ffill().bfill()\n",
        "            print(\"Missing values after initial merge filled using ffill and bfill.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during merge operation (Traffic & Air Quality): {e}\")\n",
        "            merged = None\n",
        "\n",
        "        if merged is not None and not merged.empty:\n",
        "            try:\n",
        "                # 1. Create lagged features\n",
        "                if 'traffic_volume' in merged.columns:\n",
        "                    merged['traffic_volume_lag1'] = merged['traffic_volume'].shift(1)\n",
        "                    merged['traffic_volume_lag24'] = merged['traffic_volume'].shift(24)\n",
        "                    print(\"Lagged traffic_volume features created.\")\n",
        "                else:\n",
        "                     print(\"Warning: 'traffic_volume' column not found for lagged feature creation.\")\n",
        "\n",
        "                if 'PM2.5' in merged.columns:\n",
        "                    merged['PM2.5_lag1'] = merged['PM2.5'].shift(1)\n",
        "                    merged['PM2.5_lag24'] = merged['PM2.5'].shift(24)\n",
        "                    merged['PM2.5_future'] = merged['PM2.5'].shift(-2)\n",
        "                    print(\"Lagged PM2.5 and PM2.5_future features created.\")\n",
        "                else:\n",
        "                    print(\"Warning: 'PM2.5' column not found for lagged and future feature creation.\")\n",
        "\n",
        "\n",
        "                # 2. Engineer interaction terms\n",
        "                if 'temp' in merged.columns and 'traffic_volume' in merged.columns:\n",
        "                    merged['temp_traffic_interaction'] = merged['temp'] * merged['traffic_volume']\n",
        "                    print(\"Temperature-Traffic interaction term created.\")\n",
        "                else:\n",
        "                    print(\"Warning: Required columns for 'temp_traffic_interaction' not found.\")\n",
        "\n",
        "                if 'rain_1h' in merged.columns and 'traffic_volume' in merged.columns:\n",
        "                     merged['rain_traffic_interaction'] = merged['rain_1h'] * merged['traffic_volume']\n",
        "                     print(\"Rain-Traffic interaction term created.\")\n",
        "                else:\n",
        "                    print(\"Warning: Required columns for 'rain_traffic_interaction' not found.\")\n",
        "\n",
        "                if 'PM2.5' in merged.columns and 'traffic_volume' in merged.columns:\n",
        "                    if (merged['PM2.5'] + 1).min() > 0:\n",
        "                         merged['traffic_pollution_ratio'] = merged['traffic_volume'] / (merged['PM2.5'] + 1)\n",
        "                         print(\"Traffic-Pollution ratio created.\")\n",
        "                    else:\n",
        "                         print(\"Warning: Cannot create 'traffic_pollution_ratio' due to zero or missing PM2.5 values after imputation.\")\n",
        "                         merged['traffic_pollution_ratio'] = np.nan\n",
        "\n",
        "                else:\n",
        "                    print(\"Warning: Required columns for 'traffic_pollution_ratio' not found.\")\n",
        "\n",
        "\n",
        "                # 3. Extract additional time-based features (if not already present and needed)\n",
        "                if 'date_time' in merged.columns:\n",
        "                    if 'hour' not in merged.columns:\n",
        "                         merged['hour'] = merged['date_time'].dt.hour\n",
        "                         print(\"'hour' feature created.\")\n",
        "                    if 'day' not in merged.columns:\n",
        "                         merged['day'] = merged['date_time'].dt.day\n",
        "                         print(\"'day' feature created.\")\n",
        "                    if 'weekday' not in merged.columns:\n",
        "                         merged['weekday'] = merged['date_time'].dt.weekday\n",
        "                         print(\"'weekday' feature created.\")\n",
        "                    if 'is_weekend' not in merged.columns:\n",
        "                        merged['is_weekend'] = merged['weekday'].isin([5,6]).astype(int)\n",
        "                        print(\"'is_weekend' feature created.\")\n",
        "                    if 'month' not in merged.columns:\n",
        "                        merged['month'] = merged['date_time'].dt.month\n",
        "                        print(\"'month' feature created.\")\n",
        "                    if 'year' not in merged.columns:\n",
        "                        merged['year'] = merged['date_time'].dt.year\n",
        "                        print(\"'year' feature created.\")\n",
        "                else:\n",
        "                    print(\"Warning: 'date_time' column not found for time-based feature extraction.\")\n",
        "\n",
        "\n",
        "                # 4. Integrate features from weather DataFrame\n",
        "                if 'weather' in globals() and weather is not None and 'Formatted Date' in weather.columns:\n",
        "                    try:\n",
        "                        if not pd.api.types.is_datetime64_any_dtype(weather['Formatted Date']):\n",
        "                             weather['Formatted Date'] = pd.to_datetime(weather['Formatted Date'], utc=True).dt.tz_convert(None)\n",
        "\n",
        "                        merged.sort_values('date_time', inplace=True)\n",
        "                        weather.sort_values('Formatted Date', inplace=True)\n",
        "\n",
        "                        merged = pd.merge_asof(merged,\n",
        "                                               weather,\n",
        "                                               left_on='date_time',\n",
        "                                               right_on='Formatted Date',\n",
        "                                               direction='nearest')\n",
        "                        print(\"Merged with Weather DataFrame.\")\n",
        "\n",
        "                        if 'Formatted Date' in merged.columns and 'date_time' in merged.columns and 'Formatted Date' != 'date_time':\n",
        "                             merged = merged.drop(columns=['Formatted Date'])\n",
        "                             print(\"'Formatted Date' column from weather dropped after merge.\")\n",
        "\n",
        "                        merged = merged.ffill().bfill()\n",
        "                        print(\"Missing values after weather merge filled.\")\n",
        "\n",
        "\n",
        "                    except Exception as e:\n",
        "                         print(f\"Error merging with weather data: {e}\")\n",
        "                else:\n",
        "                    print(\"Warning: Weather DataFrame not available or missing 'Formatted Date' column for merging.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during feature engineering: {e}\")\n",
        "                merged = None # Ensure merged is None if feature engineering fails\n",
        "\n",
        "            print(\"\\nFeature Engineering and Data Preparation Summary:\")\n",
        "            display(merged.head())\n",
        "            print(\"\\nShape of merged DataFrame after feature engineering:\", merged.shape)\n",
        "            print(\"\\nEngineered columns:\", [col for col in merged.columns if any(keyword in col for keyword in ['lag', 'interaction', 'ratio', 'hour', 'day', 'weekday', 'is_weekend', 'month', 'year', 'Summary', 'Temperature (C)', 'Humidity', 'Wind Speed (km/h)'])]) # List some expected new columns\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"Skipping feature engineering as merged DataFrame is not available or empty after initial merge.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during Feature Engineering and Data Preparation: {e}\")\n",
        "        merged = None\n",
        "\n",
        "# --- Model Tuning ---\n",
        "if merged is not None and not merged.empty:\n",
        "    try:\n",
        "        print(\"\\n--- Traffic Volume Classification Model Tuning ---\")\n",
        "        # 1. Define feature set (X) and target (y) for classification\n",
        "        classification_features = ['hour', 'is_weekend', 'temp', 'rain_1h', 'PM2.5',\n",
        "                                   'traffic_volume_lag1', 'PM2.5_lag1', 'temp_traffic_interaction',\n",
        "                                   'rain_traffic_interaction']\n",
        "\n",
        "        if all(col in merged.columns for col in classification_features + ['traffic_volume']):\n",
        "            merged_classification = merged.dropna(subset=classification_features + ['traffic_volume']).copy()\n",
        "\n",
        "            if merged_classification.shape[0] > 1:\n",
        "                X_classification = merged_classification[classification_features]\n",
        "                y_classification = pd.cut(merged_classification['traffic_volume'], bins=3, labels=['Low','Medium','High'])\n",
        "\n",
        "                if len(y_classification.unique()) > 1:\n",
        "                    X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(\n",
        "                        X_classification, y_classification, test_size=0.2, random_state=42, stratify=y_classification)\n",
        "                    print(f\"Classification data split successfully. Train shape: {X_train_classification.shape}, Test shape: {X_test_classification.shape}\")\n",
        "\n",
        "                    # 2. Define parameter grid for RandomForestClassifier\n",
        "                    param_grid_rfc = {\n",
        "                        'n_estimators': [50, 100, 200],\n",
        "                        'max_depth': [None, 10, 20],\n",
        "                        'min_samples_split': [2, 5, 10],\n",
        "                        'min_samples_leaf': [1, 2, 4]\n",
        "                    }\n",
        "\n",
        "                    # 3. Instantiate GridSearchCV for RandomForestClassifier\n",
        "                    cv_rfc = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "                    grid_search_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                                                   param_grid=param_grid_rfc,\n",
        "                                                   cv=cv_rfc,\n",
        "                                                   scoring='accuracy',\n",
        "                                                   n_jobs=-1)\n",
        "\n",
        "                    # 4. Fit GridSearchCV\n",
        "                    print(\"Starting GridSearchCV for RandomForestClassifier...\")\n",
        "                    grid_search_rfc.fit(X_train_classification, y_train_classification)\n",
        "                    print(\"GridSearchCV for RandomForestClassifier completed.\")\n",
        "\n",
        "                    # 5. Print best parameters and score\n",
        "                    print(\"Best parameters for RandomForestClassifier:\", grid_search_rfc.best_params_)\n",
        "                    print(\"Best cross-validation accuracy for RandomForestClassifier:\", grid_search_rfc.best_score_)\n",
        "\n",
        "                    # 6. Train final RandomForestClassifier model with best parameters\n",
        "                    model_tuned_classification = grid_search_rfc.best_estimator_\n",
        "                    print(\"Final RandomForestClassifier model trained with best parameters.\")\n",
        "\n",
        "                    # 7. Evaluate the tuned model\n",
        "                    print(\"\\nEvaluating Tuned RandomForestClassifier on Test Set:\")\n",
        "                    y_pred_classification = model_tuned_classification.predict(X_test_classification)\n",
        "                    print(\"Classification Report:\")\n",
        "                    print(classification_report(y_test_classification, y_pred_classification))\n",
        "                    print(\"\\nConfusion Matrix:\")\n",
        "                    print(confusion_matrix(y_test_classification, y_pred_classification))\n",
        "\n",
        "                else:\n",
        "                    print(\"Error during classification tuning: Target variable has only one class after binning on cleaned data.\")\n",
        "            else:\n",
        "                print(\"Error during classification tuning: Insufficient data after handling missing values.\")\n",
        "        else:\n",
        "            print(\"Error during classification tuning: Merged DataFrame is missing required columns for classification.\")\n",
        "\n",
        "\n",
        "        # --- PM2.5 Regression Model Tuning ---\n",
        "        print(\"\\n--- PM2.5 Regression Model Tuning ---\")\n",
        "\n",
        "        # 1. Define feature set (X) and target (y) for regression\n",
        "        regression_features = ['hour','traffic_volume','temp', 'PM2.5_lag1', 'traffic_volume_lag1',\n",
        "                               'temp_traffic_interaction']\n",
        "        regression_target = 'PM2.5_future'\n",
        "\n",
        "        if all(col in merged.columns for col in regression_features + [regression_target]):\n",
        "            merged_regression = merged.dropna(subset=regression_features + [regression_target]).copy()\n",
        "\n",
        "            if merged_regression.shape[0] > 1:\n",
        "                X_regression = merged_regression[regression_features]\n",
        "                y_regression = merged_regression[regression_target]\n",
        "\n",
        "                X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(\n",
        "                    X_regression, y_regression, test_size=0.2, random_state=42)\n",
        "                print(f\"Regression data split successfully. Train shape: {X_train_regression.shape}, Test shape: {X_test_regression.shape}\")\n",
        "\n",
        "                # 2. Define parameter grid for GradientBoostingRegressor\n",
        "                param_grid_gbr = {\n",
        "                    'n_estimators': [50, 100, 200],\n",
        "                    'learning_rate': [0.01, 0.1, 0.5],\n",
        "                    'max_depth': [3, 5, 10],\n",
        "                    'min_samples_split': [2, 5, 10],\n",
        "                    'min_samples_leaf': [1, 2, 4]\n",
        "                }\n",
        "\n",
        "                # 3. Instantiate GridSearchCV for GradientBoostingRegressor\n",
        "                cv_gbr = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "                grid_search_gbr = GridSearchCV(estimator=GradientBoostingRegressor(random_state=42),\n",
        "                                               param_grid=param_grid_gbr,\n",
        "                                               cv=cv_gbr,\n",
        "                                               scoring='neg_mean_squared_error',\n",
        "                                               n_jobs=-1)\n",
        "\n",
        "                # 4. Fit GridSearchCV\n",
        "                print(\"Starting GridSearchCV for GradientBoostingRegressor...\")\n",
        "                grid_search_gbr.fit(X_train_regression, y_train_regression)\n",
        "                print(\"GridSearchCV for GradientBoostingRegressor completed.\")\n",
        "\n",
        "\n",
        "                # 5. Print best parameters and score\n",
        "                print(\"Best parameters for GradientBoostingRegressor:\", grid_search_gbr.best_params_)\n",
        "                print(\"Best cross-validation MSE for GradientBoostingRegressor:\", -grid_search_gbr.best_score_)\n",
        "\n",
        "                # 6. Train final GradientBoostingRegressor model with best parameters\n",
        "                model_tuned_regression = grid_search_gbr.best_estimator_\n",
        "                print(\"Final GradientBoostingRegressor model trained with best parameters.\")\n",
        "\n",
        "                # 7. Evaluate the tuned model\n",
        "                print(\"\\nEvaluating Tuned GradientBoostingRegressor on Test Set:\")\n",
        "                y_pred_regression = model_tuned_regression.predict(X_test_regression)\n",
        "                print(\"Mean Absolute Error:\", mean_absolute_error(y_test_regression, y_pred_regression))\n",
        "                print(\"Mean Squared Error:\", mean_squared_error(y_test_regression, y_pred_regression))\n",
        "                print(\"R2 Score:\", r2_score(y_test_regression, y_pred_regression))\n",
        "\n",
        "            else:\n",
        "                 print(\"Error during regression tuning: Insufficient data after handling missing values for regression.\")\n",
        "        else:\n",
        "            print(\"Error during regression tuning: Merged DataFrame is missing required columns for regression.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during model tuning: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping model tuning as merged DataFrame is not available or empty.\")\n",
        "\n",
        "# 1. Print the classification report and confusion matrix for the tuned classification model\n",
        "print(\"\\n--- Traffic Volume Classification Model Performance ---\")\n",
        "if model_tuned_classification is not None and X_test_classification is not None and y_test_classification is not None:\n",
        "    y_pred_classification = model_tuned_classification.predict(X_test_classification)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test_classification, y_pred_classification))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test_classification, y_pred_classification))\n",
        "else:\n",
        "    print(\"Classification model or test data not available for reporting.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Data Loading ---\n",
            "All CSV files loaded successfully.\n",
            "\n",
            "Starting data cleaning and imputation...\n",
            "\n",
            "Missing values before imputation:\n",
            "Traffic:\n",
            " holiday                48143\n",
            "temp                       0\n",
            "rain_1h                    0\n",
            "snow_1h                    0\n",
            "clouds_all                 0\n",
            "weather_main               0\n",
            "weather_description        0\n",
            "date_time                  0\n",
            "traffic_volume             0\n",
            "dtype: int64\n",
            "\n",
            "Air Quality:\n",
            " City              0\n",
            "Date              0\n",
            "PM2.5          4255\n",
            "PM10          10702\n",
            "NO             4509\n",
            "NO2            3159\n",
            "NOx            4021\n",
            "NH3            9785\n",
            "CO             1999\n",
            "SO2            3499\n",
            "O3             3510\n",
            "Benzene        5122\n",
            "Toluene        7409\n",
            "Xylene        16417\n",
            "AQI            4251\n",
            "AQI_Bucket     4251\n",
            "dtype: int64\n",
            "\n",
            "Weather:\n",
            " Formatted Date                0\n",
            "Summary                       0\n",
            "Precip Type                 517\n",
            "Temperature (C)               0\n",
            "Apparent Temperature (C)      0\n",
            "Humidity                      0\n",
            "Wind Speed (km/h)             0\n",
            "Wind Bearing (degrees)        0\n",
            "Visibility (km)               0\n",
            "Loud Cover                    0\n",
            "Pressure (millibars)          0\n",
            "Daily Summary                 0\n",
            "dtype: int64\n",
            "Processed traffic 'date_time' column.\n",
            "Processed air_quality 'Date' column.\n",
            "Processed weather 'Formatted Date' column.\n",
            "Traffic data imputed.\n",
            "Air quality data (excluding PM2.5) imputed.\n",
            "PM2.5 imputed using linear interpolation.\n",
            "Weather data imputed.\n",
            "\n",
            "Missing values after imputation:\n",
            "Traffic:\n",
            " holiday                0\n",
            "temp                   0\n",
            "rain_1h                0\n",
            "snow_1h                0\n",
            "clouds_all             0\n",
            "weather_main           0\n",
            "weather_description    0\n",
            "date_time              0\n",
            "traffic_volume         0\n",
            "dtype: int64\n",
            "\n",
            "Air Quality:\n",
            " City          0\n",
            "Date          0\n",
            "PM2.5         0\n",
            "PM10          0\n",
            "NO            0\n",
            "NO2           0\n",
            "NOx           0\n",
            "NH3           0\n",
            "CO            0\n",
            "SO2           0\n",
            "O3            0\n",
            "Benzene       0\n",
            "Toluene       0\n",
            "Xylene        0\n",
            "AQI           0\n",
            "AQI_Bucket    0\n",
            "dtype: int64\n",
            "\n",
            "Weather:\n",
            " Formatted Date              0\n",
            "Summary                     0\n",
            "Precip Type                 0\n",
            "Temperature (C)             0\n",
            "Apparent Temperature (C)    0\n",
            "Humidity                    0\n",
            "Wind Speed (km/h)           0\n",
            "Wind Bearing (degrees)      0\n",
            "Visibility (km)             0\n",
            "Loud Cover                  0\n",
            "Pressure (millibars)        0\n",
            "Daily Summary               0\n",
            "dtype: int64\n",
            "\n",
            "--- Starting Feature Engineering and Data Preparation ---\n",
            "Traffic and Air Quality DataFrames merged successfully.\n",
            "Missing values after initial merge filled using ffill and bfill.\n",
            "Lagged traffic_volume features created.\n",
            "Lagged PM2.5 and PM2.5_future features created.\n",
            "Temperature-Traffic interaction term created.\n",
            "Rain-Traffic interaction term created.\n",
            "Traffic-Pollution ratio created.\n",
            "'hour' feature created.\n",
            "'day' feature created.\n",
            "'weekday' feature created.\n",
            "'is_weekend' feature created.\n",
            "'month' feature created.\n",
            "'year' feature created.\n",
            "Merged with Weather DataFrame.\n",
            "'Formatted Date' column from weather dropped after merge.\n",
            "Missing values after weather merge filled.\n",
            "\n",
            "Feature Engineering and Data Preparation Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     holiday    temp  rain_1h  snow_1h  clouds_all weather_main  \\\n",
              "0  Labor Day  288.28      0.0      0.0          40       Clouds   \n",
              "1  Labor Day  289.36      0.0      0.0          75       Clouds   \n",
              "2  Labor Day  289.58      0.0      0.0          90       Clouds   \n",
              "3  Labor Day  290.13      0.0      0.0          90       Clouds   \n",
              "4  Labor Day  291.14      0.0      0.0          75       Clouds   \n",
              "\n",
              "  weather_description           date_time  traffic_volume    City  ...  \\\n",
              "0    scattered clouds 2012-10-02 09:00:00            5545  Mumbai  ...   \n",
              "1       broken clouds 2012-10-02 10:00:00            4516  Mumbai  ...   \n",
              "2     overcast clouds 2012-10-02 11:00:00            4767  Mumbai  ...   \n",
              "3     overcast clouds 2012-10-02 12:00:00            5026  Mumbai  ...   \n",
              "4       broken clouds 2012-10-02 13:00:00            4918  Mumbai  ...   \n",
              "\n",
              "  Precip Type  Temperature (C)  Apparent Temperature (C)  Humidity  \\\n",
              "0        rain        21.150000                 21.150000      0.86   \n",
              "1        rain        22.755556                 22.755556      0.83   \n",
              "2        rain        23.794444                 23.794444      0.74   \n",
              "3        rain        23.905556                 23.905556      0.68   \n",
              "4        rain        23.688889                 23.688889      0.67   \n",
              "\n",
              "   Wind Speed (km/h)  Wind Bearing (degrees)  Visibility (km)  Loud Cover  \\\n",
              "0             8.5008                     6.0           9.8371         0.0   \n",
              "1            12.3326                    20.0          11.2700         0.0   \n",
              "2            16.4703                    49.0          11.2700         0.0   \n",
              "3            14.8925                    51.0          10.4006         0.0   \n",
              "4            13.4435                    58.0          10.0464         0.0   \n",
              "\n",
              "   Pressure (millibars)                      Daily Summary  \n",
              "0               1016.34  Partly cloudy throughout the day.  \n",
              "1               1016.30  Partly cloudy throughout the day.  \n",
              "2               1015.22  Partly cloudy throughout the day.  \n",
              "3               1014.49  Partly cloudy throughout the day.  \n",
              "4               1014.00  Partly cloudy throughout the day.  \n",
              "\n",
              "[5 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eab97742-c303-46c6-bf45-e3b1a26a3e5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>holiday</th>\n",
              "      <th>temp</th>\n",
              "      <th>rain_1h</th>\n",
              "      <th>snow_1h</th>\n",
              "      <th>clouds_all</th>\n",
              "      <th>weather_main</th>\n",
              "      <th>weather_description</th>\n",
              "      <th>date_time</th>\n",
              "      <th>traffic_volume</th>\n",
              "      <th>City</th>\n",
              "      <th>...</th>\n",
              "      <th>Precip Type</th>\n",
              "      <th>Temperature (C)</th>\n",
              "      <th>Apparent Temperature (C)</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind Speed (km/h)</th>\n",
              "      <th>Wind Bearing (degrees)</th>\n",
              "      <th>Visibility (km)</th>\n",
              "      <th>Loud Cover</th>\n",
              "      <th>Pressure (millibars)</th>\n",
              "      <th>Daily Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Labor Day</td>\n",
              "      <td>288.28</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>scattered clouds</td>\n",
              "      <td>2012-10-02 09:00:00</td>\n",
              "      <td>5545</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>...</td>\n",
              "      <td>rain</td>\n",
              "      <td>21.150000</td>\n",
              "      <td>21.150000</td>\n",
              "      <td>0.86</td>\n",
              "      <td>8.5008</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.8371</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1016.34</td>\n",
              "      <td>Partly cloudy throughout the day.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Labor Day</td>\n",
              "      <td>289.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>2012-10-02 10:00:00</td>\n",
              "      <td>4516</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>...</td>\n",
              "      <td>rain</td>\n",
              "      <td>22.755556</td>\n",
              "      <td>22.755556</td>\n",
              "      <td>0.83</td>\n",
              "      <td>12.3326</td>\n",
              "      <td>20.0</td>\n",
              "      <td>11.2700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1016.30</td>\n",
              "      <td>Partly cloudy throughout the day.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Labor Day</td>\n",
              "      <td>289.58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>overcast clouds</td>\n",
              "      <td>2012-10-02 11:00:00</td>\n",
              "      <td>4767</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>...</td>\n",
              "      <td>rain</td>\n",
              "      <td>23.794444</td>\n",
              "      <td>23.794444</td>\n",
              "      <td>0.74</td>\n",
              "      <td>16.4703</td>\n",
              "      <td>49.0</td>\n",
              "      <td>11.2700</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1015.22</td>\n",
              "      <td>Partly cloudy throughout the day.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Labor Day</td>\n",
              "      <td>290.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>overcast clouds</td>\n",
              "      <td>2012-10-02 12:00:00</td>\n",
              "      <td>5026</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>...</td>\n",
              "      <td>rain</td>\n",
              "      <td>23.905556</td>\n",
              "      <td>23.905556</td>\n",
              "      <td>0.68</td>\n",
              "      <td>14.8925</td>\n",
              "      <td>51.0</td>\n",
              "      <td>10.4006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1014.49</td>\n",
              "      <td>Partly cloudy throughout the day.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Labor Day</td>\n",
              "      <td>291.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75</td>\n",
              "      <td>Clouds</td>\n",
              "      <td>broken clouds</td>\n",
              "      <td>2012-10-02 13:00:00</td>\n",
              "      <td>4918</td>\n",
              "      <td>Mumbai</td>\n",
              "      <td>...</td>\n",
              "      <td>rain</td>\n",
              "      <td>23.688889</td>\n",
              "      <td>23.688889</td>\n",
              "      <td>0.67</td>\n",
              "      <td>13.4435</td>\n",
              "      <td>58.0</td>\n",
              "      <td>10.0464</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1014.00</td>\n",
              "      <td>Partly cloudy throughout the day.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eab97742-c303-46c6-bf45-e3b1a26a3e5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eab97742-c303-46c6-bf45-e3b1a26a3e5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eab97742-c303-46c6-bf45-e3b1a26a3e5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-83a67842-b91b-433c-a75f-240ab53544ec\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83a67842-b91b-433c-a75f-240ab53544ec')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-83a67842-b91b-433c-a75f-240ab53544ec button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of merged DataFrame after feature engineering: (48204, 50)\n",
            "\n",
            "Engineered columns: ['holiday', 'traffic_volume_lag1', 'traffic_volume_lag24', 'PM2.5_lag1', 'PM2.5_lag24', 'temp_traffic_interaction', 'rain_traffic_interaction', 'traffic_pollution_ratio', 'hour', 'day', 'weekday', 'is_weekend', 'month', 'year', 'Summary', 'Temperature (C)', 'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'Daily Summary']\n",
            "\n",
            "--- Traffic Volume Classification Model Tuning ---\n",
            "Classification data split successfully. Train shape: (38563, 9), Test shape: (9641, 9)\n",
            "Starting GridSearchCV for RandomForestClassifier...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de79e6f7"
      },
      "source": [
        "## Project Summary\n",
        "\n",
        "Developed a data science project analyzing urban traffic and air quality using integrated datasets. Performed data cleaning, feature engineering with lagged variables and interaction terms, and built machine learning models (RandomForestClassifier for traffic volume classification and GradientBoostingRegressor for PM2.5 regression). Evaluated model performance using metrics such as accuracy for classification and MAE, MSE, and R2 for regression. Created an interactive dashboard to visualize trends and relationships."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(app.run_server(mode='external')))"
      ],
      "metadata": {
        "id": "nidkn1YbR8je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcbbfc55"
      },
      "source": [
        "import dash\n",
        "from dash import dcc\n",
        "from dash import html\n",
        "from dash.dependencies import Input, Output\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "if 'merged' in globals() and merged is not None and not merged.empty:\n",
        "    df = merged.copy()\n",
        "\n",
        "    if not pd.api.types.is_datetime64_any_dtype(df['date_time']):\n",
        "        try:\n",
        "            df['date_time'] = pd.to_datetime(df['date_time'])\n",
        "            if df['date_time'].dt.tz:\n",
        "                 df['date_time'] = df['date_time'].dt.tz_convert(None)\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting date_time to datetime: {e}\")\n",
        "            df = None\n",
        "\n",
        "\n",
        "    if df is not None:\n",
        "        app = dash.Dash(__name__)\n",
        "\n",
        "        app.layout = html.Div([\n",
        "            html.H1(\"Traffic Volume and PM2.5 Analysis Dashboard\"),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Time Series Analysis\"),\n",
        "                dcc.Graph(id='time-series-traffic'),\n",
        "                dcc.Graph(id='time-series-pm25')\n",
        "            ]),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Scatter Plot: Traffic Volume vs. Temperature\"),\n",
        "                dcc.Graph(id='scatter-traffic-temp')\n",
        "            ]),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Distribution Analysis\"),\n",
        "                dcc.Graph(id='hist-traffic'),\n",
        "                dcc.Graph(id='hist-pm25')\n",
        "            ]),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Weather Condition Analysis\"),\n",
        "                dcc.Graph(id='bar-weather-traffic')\n",
        "            ]),\n",
        "\n",
        "            html.Div([\n",
        "                html.H3(\"Date Range Slider\"),\n",
        "                dcc.RangeSlider(\n",
        "                    id='date-range-slider',\n",
        "                    min=0,\n",
        "                    max=len(df['date_time']) - 1,\n",
        "                    value=[0, len(df['date_time']) - 1],\n",
        "                    marks={i: df['date_time'].iloc[i].strftime('%Y-%m-%d') for i in range(0, len(df['date_time']), len(df) // 5)}, # Example marks\n",
        "                    step=1\n",
        "                )\n",
        "            ])\n",
        "        ])\n",
        "\n",
        "        @app.callback(\n",
        "            [Output('time-series-traffic', 'figure'),\n",
        "             Output('time-series-pm25', 'figure'),\n",
        "             Output('scatter-traffic-temp', 'figure'),\n",
        "             Output('hist-traffic', 'figure'),\n",
        "             Output('hist-pm25', 'figure'),\n",
        "             Output('bar-weather-traffic', 'figure')],\n",
        "            [Input('date-range-slider', 'value')]\n",
        "        )\n",
        "        def update_graphs(date_range):\n",
        "            if df is None:\n",
        "                return {}, {}, {}, {}, {}, {} # Return empty figures if df is None\n",
        "\n",
        "            start_index, end_index = date_range\n",
        "            filtered_df = df.iloc[start_index:end_index+1]\n",
        "\n",
        "            # Time Series Traffic\n",
        "            fig_traffic_ts = px.line(filtered_df, x='date_time', y='traffic_volume', title='Traffic Volume Over Time')\n",
        "\n",
        "            # Time Series PM2.5\n",
        "            fig_pm25_ts = px.line(filtered_df, x='date_time', y='PM2.5', title='PM2.5 Levels Over Time')\n",
        "\n",
        "            # Scatter Traffic vs Temp\n",
        "            fig_scatter_temp = px.scatter(filtered_df, x='temp', y='traffic_volume', title='Traffic Volume vs. Temperature')\n",
        "\n",
        "            # Histogram Traffic\n",
        "            fig_hist_traffic = px.histogram(filtered_df, x='traffic_volume', title='Distribution of Traffic Volume')\n",
        "\n",
        "            # Histogram PM2.5\n",
        "            fig_hist_pm25 = px.histogram(filtered_df, x='PM2.5', title='Distribution of PM2.5 Levels')\n",
        "\n",
        "            # Bar Weather vs Traffic\n",
        "            if 'weather_main' in filtered_df.columns:\n",
        "                weather_traffic = filtered_df.groupby('weather_main')['traffic_volume'].mean().reset_index()\n",
        "                fig_bar_weather_traffic = px.bar(weather_traffic, x='weather_main', y='traffic_volume', title='Average Traffic Volume by Weather Condition')\n",
        "            else:\n",
        "                fig_bar_weather_traffic = {}\n",
        "\n",
        "\n",
        "            return fig_traffic_ts, fig_pm25_ts, fig_scatter_temp, fig_hist_traffic, fig_hist_pm25, fig_bar_weather_traffic\n",
        "\n",
        "        print(\"Dash app defined. To run the app in Colab, you can use:\")\n",
        "        print(\"from google.colab.output import eval_js\")\n",
        "        print(\"print(eval_js(app.run_server(mode='external')))\")\n",
        "\n",
        "    else:\n",
        "        print(\"DataFrame 'merged' not available or empty. Cannot define Dash app.\")\n",
        "\n",
        "else:\n",
        "    print(\"DataFrame 'merged' not available or empty. Cannot define Dash app.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8ee8c55"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "merged = None\n",
        "model_tuned_classification = None\n",
        "model_tuned_regression = None\n",
        "X_train_classification = None\n",
        "X_test_classification = None\n",
        "y_train_classification = None\n",
        "y_test_classification = None\n",
        "X_train_regression = None\n",
        "X_test_regression = None\n",
        "y_train_regression = None\n",
        "y_test_regression = None\n",
        "\n",
        "traffic_filename = \"Metro_Interstate_Traffic_Volume.csv\"\n",
        "air_quality_filename = \"city_day.csv\"\n",
        "weather_filename = \"weatherHistory.csv\"\n",
        "\n",
        "try:\n",
        "    print(\"--- Starting Data Loading ---\")\n",
        "    if os.path.exists(traffic_filename) and os.path.exists(air_quality_filename) and os.path.exists(weather_filename):\n",
        "        try:\n",
        "            traffic = pd.read_csv(traffic_filename)\n",
        "            air_quality = pd.read_csv(air_quality_filename)\n",
        "            weather = pd.read_csv(weather_filename)\n",
        "            print(\"All CSV files loaded successfully.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading CSV files: {e}\")\n",
        "            traffic, air_quality, weather = None, None, None\n",
        "    else:\n",
        "        print(\"Error: One or more CSV files not found in the expected location after upload.\")\n",
        "        traffic, air_quality, weather = None, None, None\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during data loading: {e}\")\n",
        "    traffic, air_quality, weather = None, None, None\n",
        "\n",
        "if traffic is not None and air_quality is not None and weather is not None:\n",
        "    try:\n",
        "        print(\"\\nStarting data cleaning and imputation...\")\n",
        "\n",
        "        print(\"\\nMissing values before imputation:\")\n",
        "        print(\"Traffic:\\n\", traffic.isnull().sum())\n",
        "        print(\"\\nAir Quality:\\n\", air_quality.isnull().sum())\n",
        "        print(\"\\nWeather:\\n\", weather.isnull().sum())\n",
        "\n",
        "        try:\n",
        "            if 'date_time' in traffic.columns:\n",
        "                traffic['date_time'] = pd.to_datetime(traffic['date_time'])\n",
        "                if traffic['date_time'].dt.tz:\n",
        "                    traffic['date_time'] = traffic['date_time'].dt.tz_convert(None)\n",
        "                print(\"Processed traffic 'date_time' column.\")\n",
        "            else:\n",
        "                 print(\"Warning: 'date_time' column not found in traffic DataFrame.\")\n",
        "\n",
        "\n",
        "            if 'Date' in air_quality.columns:\n",
        "                air_quality['Date'] = pd.to_datetime(air_quality['Date'])\n",
        "                if air_quality['Date'].dt.tz:\n",
        "                    air_quality['Date'] = air_quality['Date'].dt.tz_convert(None)\n",
        "                print(\"Processed air_quality 'Date' column.\")\n",
        "            else:\n",
        "                 print(\"Warning: 'Date' column not found in air_quality DataFrame.\")\n",
        "\n",
        "\n",
        "            if 'Formatted Date' in weather.columns:\n",
        "                 weather['Formatted Date'] = pd.to_datetime(weather['Formatted Date'], utc=True).dt.tz_convert(None)\n",
        "                 print(\"Processed weather 'Formatted Date' column.\")\n",
        "            else:\n",
        "                 print(\"Warning: 'Formatted Date' column not found in weather DataFrame.\")\n",
        "\n",
        "\n",
        "        except (ValueError, TypeError) as e:\n",
        "            print(f\"Error converting date columns: {e}\")\n",
        "\n",
        "        for col in traffic.select_dtypes(include=['float64', 'int64']).columns:\n",
        "            if traffic[col].isnull().any():\n",
        "                mean_val = traffic[col].mean()\n",
        "                traffic[col] = traffic[col].fillna(mean_val)\n",
        "\n",
        "        for col in traffic.select_dtypes(include=['object']).columns:\n",
        "            if traffic[col].isnull().any():\n",
        "                mode_val = traffic[col].mode()[0]\n",
        "                traffic[col] = traffic[col].fillna(mode_val)\n",
        "        print(\"Traffic data imputed.\")\n",
        "\n",
        "        for col in air_quality.select_dtypes(include=['float64', 'int64']).columns:\n",
        "            if col != 'PM2.5' and air_quality[col].isnull().any():\n",
        "                mean_val = air_quality[col].mean()\n",
        "                air_quality[col] = air_quality[col].fillna(mean_val)\n",
        "\n",
        "        for col in air_quality.select_dtypes(include=['object']).columns:\n",
        "            if air_quality[col].isnull().any():\n",
        "                mode_val = air_quality[col].mode()[0]\n",
        "                air_quality[col] = air_quality[col].fillna(mode_val)\n",
        "        print(\"Air quality data (excluding PM2.5) imputed.\")\n",
        "\n",
        "        if 'PM2.5' in air_quality.columns and air_quality['PM2.5'].isnull().any():\n",
        "            air_quality.sort_values(by='Date', inplace=True)\n",
        "            air_quality['PM2.5'] = air_quality['PM2.5'].interpolate(method='linear').ffill().bfill() # Add ffill/bfill for edge cases\n",
        "            print(\"PM2.5 imputed using linear interpolation.\")\n",
        "        elif 'PM2.5' in air_quality.columns:\n",
        "            print(\"No missing values in PM2.5.\")\n",
        "        else:\n",
        "            print(\"Warning: 'PM2.5' column not found in air_quality DataFrame.\")\n",
        "\n",
        "        for col in weather.select_dtypes(include=['float64', 'int64']).columns:\n",
        "            if weather[col].isnull().any():\n",
        "                mean_val = weather[col].mean()\n",
        "                weather[col] = weather[col].fillna(mean_val)\n",
        "\n",
        "        for col in weather.select_dtypes(include=['object']).columns:\n",
        "            if weather[col].isnull().any():\n",
        "                mode_val = weather[col].mode()[0]\n",
        "                weather[col] = weather[col].fillna(mode_val)\n",
        "        print(\"Weather data imputed.\")\n",
        "\n",
        "        print(\"\\nMissing values after imputation:\")\n",
        "        print(\"Traffic:\\n\", traffic.isnull().sum())\n",
        "        print(\"\\nAir Quality:\\n\", air_quality.isnull().sum())\n",
        "        print(\"\\nWeather:\\n\", weather.isnull().sum())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during data cleaning and imputation: {e}\")\n",
        "        traffic, air_quality, weather = None, None, None\n",
        "\n",
        "if traffic is not None and air_quality is not None and weather is not None:\n",
        "    try:\n",
        "        print(\"\\n--- Starting Feature Engineering and Data Preparation ---\")\n",
        "\n",
        "        if 'date_time' not in traffic.columns:\n",
        "            raise ValueError(\"Traffic DataFrame is missing 'date_time' column for merging.\")\n",
        "        if 'Date' not in air_quality.columns:\n",
        "             raise ValueError(\"Air Quality DataFrame is missing 'Date' column for merging.\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            merged = pd.merge_asof(traffic.sort_values('date_time'),\n",
        "                                   air_quality.sort_values('Date'),\n",
        "                                   left_on='date_time',\n",
        "                                   right_on='Date')\n",
        "            print(\"Traffic and Air Quality DataFrames merged successfully.\")\n",
        "\n",
        "            merged = merged.ffill().bfill()\n",
        "            print(\"Missing values after initial merge filled using ffill and bfill.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during merge operation (Traffic & Air Quality): {e}\")\n",
        "            merged = None\n",
        "\n",
        "        if merged is not None and not merged.empty:\n",
        "            try:\n",
        "                # 1. Create lagged features\n",
        "                if 'traffic_volume' in merged.columns:\n",
        "                    merged['traffic_volume_lag1'] = merged['traffic_volume'].shift(1)\n",
        "                    merged['traffic_volume_lag24'] = merged['traffic_volume'].shift(24)\n",
        "                    print(\"Lagged traffic_volume features created.\")\n",
        "                else:\n",
        "                     print(\"Warning: 'traffic_volume' column not found for lagged feature creation.\")\n",
        "\n",
        "                if 'PM2.5' in merged.columns:\n",
        "                    merged['PM2.5_lag1'] = merged['PM2.5'].shift(1)\n",
        "                    merged['PM2.5_lag24'] = merged['PM2.5'].shift(24)\n",
        "                    merged['PM2.5_future'] = merged['PM2.5'].shift(-2)\n",
        "                    print(\"Lagged PM2.5 and PM2.5_future features created.\")\n",
        "                else:\n",
        "                    print(\"Warning: 'PM2.5' column not found for lagged and future feature creation.\")\n",
        "\n",
        "\n",
        "                # 2. Engineer interaction terms\n",
        "                if 'temp' in merged.columns and 'traffic_volume' in merged.columns:\n",
        "                    merged['temp_traffic_interaction'] = merged['temp'] * merged['traffic_volume']\n",
        "                    print(\"Temperature-Traffic interaction term created.\")\n",
        "                else:\n",
        "                    print(\"Warning: Required columns for 'temp_traffic_interaction' not found.\")\n",
        "\n",
        "                if 'rain_1h' in merged.columns and 'traffic_volume' in merged.columns:\n",
        "                     merged['rain_traffic_interaction'] = merged['rain_1h'] * merged['traffic_volume']\n",
        "                     print(\"Rain-Traffic interaction term created.\")\n",
        "                else:\n",
        "                    print(\"Warning: Required columns for 'rain_traffic_interaction' not found.\")\n",
        "\n",
        "                if 'PM2.5' in merged.columns and 'traffic_volume' in merged.columns:\n",
        "                    if (merged['PM2.5'] + 1).min() > 0:\n",
        "                         merged['traffic_pollution_ratio'] = merged['traffic_volume'] / (merged['PM2.5'] + 1)\n",
        "                         print(\"Traffic-Pollution ratio created.\")\n",
        "                    else:\n",
        "                         print(\"Warning: Cannot create 'traffic_pollution_ratio' due to zero or missing PM2.5 values after imputation.\")\n",
        "                         merged['traffic_pollution_ratio'] = np.nan\n",
        "\n",
        "                else:\n",
        "                    print(\"Warning: Required columns for 'traffic_pollution_ratio' not found.\")\n",
        "\n",
        "\n",
        "                # 3. Extract additional time-based features (if not already present and needed)\n",
        "                if 'date_time' in merged.columns:\n",
        "                    if 'hour' not in merged.columns:\n",
        "                         merged['hour'] = merged['date_time'].dt.hour\n",
        "                         print(\"'hour' feature created.\")\n",
        "                    if 'day' not in merged.columns:\n",
        "                         merged['day'] = merged['date_time'].dt.day\n",
        "                         print(\"'day' feature created.\")\n",
        "                    if 'weekday' not in merged.columns:\n",
        "                         merged['weekday'] = merged['date_time'].dt.weekday\n",
        "                         print(\"'weekday' feature created.\")\n",
        "                    if 'is_weekend' not in merged.columns:\n",
        "                        merged['is_weekend'] = merged['weekday'].isin([5,6]).astype(int)\n",
        "                        print(\"'is_weekend' feature created.\")\n",
        "                    if 'month' not in merged.columns:\n",
        "                        merged['month'] = merged['date_time'].dt.month\n",
        "                        print(\"'month' feature created.\")\n",
        "                    if 'year' not in merged.columns:\n",
        "                        merged['year'] = merged['date_time'].dt.year\n",
        "                        print(\"'year' feature created.\")\n",
        "                else:\n",
        "                    print(\"Warning: 'date_time' column not found for time-based feature extraction.\")\n",
        "\n",
        "\n",
        "                # 4. Integrate features from weather DataFrame\n",
        "                if 'weather' in globals() and weather is not None and 'Formatted Date' in weather.columns:\n",
        "                    try:\n",
        "                        if not pd.api.types.is_datetime64_any_dtype(weather['Formatted Date']):\n",
        "                             weather['Formatted Date'] = pd.to_datetime(weather['Formatted Date'], utc=True).dt.tz_convert(None)\n",
        "\n",
        "                        merged.sort_values('date_time', inplace=True)\n",
        "                        weather.sort_values('Formatted Date', inplace=True)\n",
        "\n",
        "                        merged = pd.merge_asof(merged,\n",
        "                                               weather,\n",
        "                                               left_on='date_time',\n",
        "                                               right_on='Formatted Date',\n",
        "                                               direction='nearest')\n",
        "                        print(\"Merged with Weather DataFrame.\")\n",
        "\n",
        "                        if 'Formatted Date' in merged.columns and 'date_time' in merged.columns and 'Formatted Date' != 'date_time':\n",
        "                             merged = merged.drop(columns=['Formatted Date'])\n",
        "                             print(\"'Formatted Date' column from weather dropped after merge.\")\n",
        "\n",
        "                        merged = merged.ffill().bfill()\n",
        "                        print(\"Missing values after weather merge filled.\")\n",
        "\n",
        "\n",
        "                    except Exception as e:\n",
        "                         print(f\"Error merging with weather data: {e}\")\n",
        "                else:\n",
        "                    print(\"Warning: Weather DataFrame not available or missing 'Formatted Date' column for merging.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during feature engineering: {e}\")\n",
        "                merged = None # Ensure merged is None if feature engineering fails\n",
        "\n",
        "            print(\"\\nFeature Engineering and Data Preparation Summary:\")\n",
        "            display(merged.head())\n",
        "            print(\"\\nShape of merged DataFrame after feature engineering:\", merged.shape)\n",
        "            print(\"\\nEngineered columns:\", [col for col in merged.columns if any(keyword in col for keyword in ['lag', 'interaction', 'ratio', 'hour', 'day', 'weekday', 'is_weekend', 'month', 'year', 'Summary', 'Temperature (C)', 'Humidity', 'Wind Speed (km/h)'])]) # List some expected new columns\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"Skipping feature engineering as merged DataFrame is not available or empty after initial merge.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during Feature Engineering and Data Preparation: {e}\")\n",
        "        merged = None\n",
        "\n",
        "# --- Model Tuning ---\n",
        "if merged is not None and not merged.empty:\n",
        "    try:\n",
        "        print(\"\\n--- Traffic Volume Classification Model Tuning ---\")\n",
        "        # 1. Define feature set (X) and target (y) for classification\n",
        "        classification_features = ['hour', 'is_weekend', 'temp', 'rain_1h', 'PM2.5',\n",
        "                                   'traffic_volume_lag1', 'PM2.5_lag1', 'temp_traffic_interaction',\n",
        "                                   'rain_traffic_interaction']\n",
        "\n",
        "        if all(col in merged.columns for col in classification_features + ['traffic_volume']):\n",
        "            merged_classification = merged.dropna(subset=classification_features + ['traffic_volume']).copy()\n",
        "\n",
        "            if merged_classification.shape[0] > 1:\n",
        "                X_classification = merged_classification[classification_features]\n",
        "                y_classification = pd.cut(merged_classification['traffic_volume'], bins=3, labels=['Low','Medium','High'])\n",
        "\n",
        "                if len(y_classification.unique()) > 1:\n",
        "                    X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(\n",
        "                        X_classification, y_classification, test_size=0.2, random_state=42, stratify=y_classification)\n",
        "                    print(f\"Classification data split successfully. Train shape: {X_train_classification.shape}, Test shape: {X_test_classification.shape}\")\n",
        "\n",
        "                    # 2. Define parameter grid for RandomForestClassifier\n",
        "                    param_grid_rfc = {\n",
        "                        'n_estimators': [50, 100, 200],\n",
        "                        'max_depth': [None, 10, 20],\n",
        "                        'min_samples_split': [2, 5, 10],\n",
        "                        'min_samples_leaf': [1, 2, 4]\n",
        "                    }\n",
        "\n",
        "                    # 3. Instantiate GridSearchCV for RandomForestClassifier\n",
        "                    cv_rfc = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "                    grid_search_rfc = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
        "                                                   param_grid=param_grid_rfc,\n",
        "                                                   cv=cv_rfc,\n",
        "                                                   scoring='accuracy',\n",
        "                                                   n_jobs=-1)\n",
        "\n",
        "                    # 4. Fit GridSearchCV\n",
        "                    print(\"Starting GridSearchCV for RandomForestClassifier...\")\n",
        "                    grid_search_rfc.fit(X_train_classification, y_train_classification)\n",
        "                    print(\"GridSearchCV for RandomForestClassifier completed.\")\n",
        "\n",
        "                    # 5. Print best parameters and score\n",
        "                    print(\"Best parameters for RandomForestClassifier:\", grid_search_rfc.best_params_)\n",
        "                    print(\"Best cross-validation accuracy for RandomForestClassifier:\", grid_search_rfc.best_score_)\n",
        "\n",
        "                    # 6. Train final RandomForestClassifier model with best parameters\n",
        "                    model_tuned_classification = grid_search_rfc.best_estimator_\n",
        "                    print(\"Final RandomForestClassifier model trained with best parameters.\")\n",
        "\n",
        "                    # 7. Evaluate the tuned model\n",
        "                    print(\"\\nEvaluating Tuned RandomForestClassifier on Test Set:\")\n",
        "                    y_pred_classification = model_tuned_classification.predict(X_test_classification)\n",
        "                    print(\"Classification Report:\")\n",
        "                    print(classification_report(y_test_classification, y_pred_classification))\n",
        "                    print(\"\\nConfusion Matrix:\")\n",
        "                    print(confusion_matrix(y_test_classification, y_pred_classification))\n",
        "\n",
        "                else:\n",
        "                    print(\"Error during classification tuning: Target variable has only one class after binning on cleaned data.\")\n",
        "            else:\n",
        "                print(\"Error during classification tuning: Insufficient data after handling missing values.\")\n",
        "        else:\n",
        "            print(\"Error during classification tuning: Merged DataFrame is missing required columns for classification.\")\n",
        "\n",
        "\n",
        "        # --- PM2.5 Regression Model Tuning ---\n",
        "        print(\"\\n--- PM2.5 Regression Model Tuning ---\")\n",
        "\n",
        "        # 1. Define feature set (X) and target (y) for regression\n",
        "        regression_features = ['hour','traffic_volume','temp', 'PM2.5_lag1', 'traffic_volume_lag1',\n",
        "                               'temp_traffic_interaction']\n",
        "        regression_target = 'PM2.5_future'\n",
        "\n",
        "        if all(col in merged.columns for col in regression_features + [regression_target]):\n",
        "            merged_regression = merged.dropna(subset=regression_features + [regression_target]).copy()\n",
        "\n",
        "            if merged_regression.shape[0] > 1:\n",
        "                X_regression = merged_regression[regression_features]\n",
        "                y_regression = merged_regression[regression_target]\n",
        "\n",
        "                X_train_regression, X_test_regression, y_train_regression, y_test_regression = train_test_split(\n",
        "                    X_regression, y_regression, test_size=0.2, random_state=42)\n",
        "                print(f\"Regression data split successfully. Train shape: {X_train_regression.shape}, Test shape: {X_test_regression.shape}\")\n",
        "\n",
        "                # 2. Define parameter grid for GradientBoostingRegressor\n",
        "                param_grid_gbr = {\n",
        "                    'n_estimators': [50, 100, 200],\n",
        "                    'learning_rate': [0.01, 0.1, 0.5],\n",
        "                    'max_depth': [3, 5, 10],\n",
        "                    'min_samples_split': [2, 5, 10],\n",
        "                    'min_samples_leaf': [1, 2, 4]\n",
        "                }\n",
        "\n",
        "                # 3. Instantiate GridSearchCV for GradientBoostingRegressor\n",
        "                cv_gbr = KFold(n_splits=3, shuffle=True, random_state=42)\n",
        "                grid_search_gbr = GridSearchCV(estimator=GradientBoostingRegressor(random_state=42),\n",
        "                                               param_grid=param_grid_gbr,\n",
        "                                               cv=cv_gbr,\n",
        "                                               scoring='neg_mean_squared_error',\n",
        "                                               n_jobs=-1)\n",
        "\n",
        "                # 4. Fit GridSearchCV\n",
        "                print(\"Starting GridSearchCV for GradientBoostingRegressor...\")\n",
        "                grid_search_gbr.fit(X_train_regression, y_train_regression)\n",
        "                print(\"GridSearchCV for GradientBoostingRegressor completed.\")\n",
        "\n",
        "\n",
        "                # 5. Print best parameters and score\n",
        "                print(\"Best parameters for GradientBoostingRegressor:\", grid_search_gbr.best_params_)\n",
        "                print(\"Best cross-validation MSE for GradientBoostingRegressor:\", -grid_search_gbr.best_score_)\n",
        "\n",
        "                # 6. Train final GradientBoostingRegressor model with best parameters\n",
        "                model_tuned_regression = grid_search_gbr.best_estimator_\n",
        "                print(\"Final GradientBoostingRegressor model trained with best parameters.\")\n",
        "\n",
        "                # 7. Evaluate the tuned model\n",
        "                print(\"\\nEvaluating Tuned GradientBoostingRegressor on Test Set:\")\n",
        "                y_pred_regression = model_tuned_regression.predict(X_test_regression)\n",
        "                print(\"Mean Absolute Error:\", mean_absolute_error(y_test_regression, y_pred_regression))\n",
        "                print(\"Mean Squared Error:\", mean_squared_error(y_test_regression, y_pred_regression))\n",
        "                print(\"R2 Score:\", r2_score(y_test_regression, y_pred_regression))\n",
        "\n",
        "            else:\n",
        "                 print(\"Error during regression tuning: Insufficient data after handling missing values for regression.\")\n",
        "        else:\n",
        "            print(\"Error during regression tuning: Merged DataFrame is missing required columns for regression.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during model tuning: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nSkipping model tuning as merged DataFrame is not available or empty.\")\n",
        "\n",
        "# 1. Print the classification report and confusion matrix for the tuned classification model\n",
        "print(\"\\n--- Traffic Volume Classification Model Performance ---\")\n",
        "if model_tuned_classification is not None and X_test_classification is not None and y_test_classification is not None:\n",
        "    y_pred_classification = model_tuned_classification.predict(X_test_classification)\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test_classification, y_pred_classification))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_test_classification, y_pred_classification))\n",
        "else:\n",
        "    print(\"Classification model or test data not available for reporting.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c6559a1"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Create a scatter plot to visualize actual vs. predicted for regression\n",
        "if model_tuned_regression is not None and X_test_regression is not None and y_test_regression is not None:\n",
        "    y_pred_regression = model_tuned_regression.predict(X_test_regression)\n",
        "    print(\"\\nCreating scatter plot for Actual vs. Predicted PM2.5 (Regression)...\")\n",
        "    fig_regression_scatter = px.scatter(x=y_test_regression, y=y_pred_regression,\n",
        "                                        labels={'x': 'Actual PM2.5', 'y': 'Predicted PM2.5'},\n",
        "                                        title='Actual vs. Predicted PM2.5 (Regression Model)')\n",
        "    fig_regression_scatter.show()\n",
        "else:\n",
        "    print(\"Regression model or test data not available for scatter plot.\")\n",
        "\n",
        "\n",
        "# Generate Confusion Matrix Heatmap for Classification Model\n",
        "if model_tuned_classification is not None and X_test_classification is not None and y_test_classification is not None:\n",
        "    y_pred_classification = model_tuned_classification.predict(X_test_classification)\n",
        "    cm = confusion_matrix(y_test_classification, y_pred_classification)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['High', 'Low', 'Medium'], yticklabels=['High', 'Low', 'Medium']) # Assuming labels based on previous output\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix for Traffic Volume Classification')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Classification model or test data not available for confusion matrix heatmap.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2df8577"
      },
      "outputs": [],
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(app.run(mode='external')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a013270"
      },
      "source": [
        "## Summarize data understanding\n",
        "\n",
        "### Subtask:\n",
        "Briefly describe the datasets used, the key variables, and any initial observations after data loading and cleaning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bb233f1"
      },
      "source": [
        "**Reasoning**:\n",
        "Access and display information about the traffic, air_quality, and weather dataframes to understand their structure and content after loading and cleaning, as requested in steps 1-4 of the instructions. This will provide the necessary details for the subsequent summary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e91d64c"
      },
      "outputs": [],
      "source": [
        "print(\"--- Traffic DataFrame Information ---\")\n",
        "display(traffic.head())\n",
        "traffic.info()\n",
        "print(\"Shape:\", traffic.shape)\n",
        "\n",
        "print(\"\\n--- Air Quality DataFrame Information ---\")\n",
        "display(air_quality.head())\n",
        "air_quality.info()\n",
        "print(\"Shape:\", air_quality.shape)\n",
        "\n",
        "print(\"\\n--- Weather DataFrame Information ---\")\n",
        "display(weather.head())\n",
        "weather.info()\n",
        "print(\"Shape:\", weather.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32740b1c"
      },
      "outputs": [],
      "source": [
        "engineered_columns = [col for col in merged.columns if any(keyword in col for keyword in ['lag', 'interaction', 'ratio', 'hour', 'day', 'weekday', 'is_weekend', 'month', 'year']) or col in ['Summary', 'Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'Daily Summary']]\n",
        "\n",
        "print(\"--- Engineered Features and Their Rationale ---\")\n",
        "\n",
        "for col in engineered_columns:\n",
        "    if 'lag' in col:\n",
        "        original_col = col.replace('_lag1', '').replace('_lag24', '')\n",
        "        lag_hours = col.split('lag')[-1]\n",
        "        print(f\"\\nFeature: {col}\")\n",
        "        print(f\"Creation: Created by shifting the '{original_col}' column by {lag_hours} hour(s).\")\n",
        "        print(\"Rationale: Captures temporal dependencies and patterns in traffic volume and PM2.5 levels from previous hours.\")\n",
        "    elif 'interaction' in col:\n",
        "        components = col.replace('_interaction', '').split('_')\n",
        "        print(f\"\\nFeature: {col}\")\n",
        "        print(f\"Creation: Created by multiplying the '{components[0]}' and '{components[1]}' columns.\")\n",
        "        print(\"Rationale: Captures the combined effect or how the relationship between two variables impacts the target variables.\")\n",
        "    elif 'ratio' in col:\n",
        "        components = col.split('_')\n",
        "        print(f\"\\nFeature: {col}\")\n",
        "        print(f\"Creation: Created by dividing '{components[0]}' by '{components[1]}' (with a small constant added to the denominator to avoid division by zero).\")\n",
        "        print(\"Rationale: Represents the relative impact of traffic compared to pollution, potentially indicating scenarios where traffic is high despite poor air quality or vice versa.\")\n",
        "    elif col in ['hour', 'day', 'weekday', 'is_weekend', 'month', 'year']:\n",
        "        print(f\"\\nFeature: {col}\")\n",
        "        print(f\"Creation: Extracted from the 'date_time' column.\")\n",
        "        print(\"Rationale: Captures daily, weekly, monthly, and annual seasonality and time-of-day patterns in traffic and pollution.\")\n",
        "    elif col in ['Summary', 'Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'Daily Summary', 'Apparent Temperature (C)', 'Pressure (millibars)', 'Visibility (km)', 'Wind Bearing (degrees)', 'Precip Type', 'Loud Cover']:\n",
        "         print(f\"\\nFeature: {col}\")\n",
        "         print(f\"Creation: Integrated from the 'weather' DataFrame through a time-based merge.\")\n",
        "         print(\"Rationale: Incorporates external environmental factors known to influence traffic and air quality.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Overall Goal of Feature Engineering ---\")\n",
        "print(\"The overall goal of feature engineering was to create new variables that better capture the complex temporal, environmental, and interactive relationships within the data.\")\n",
        "print(\"These engineered features provide richer information to the machine learning models, potentially improving their ability to predict future traffic volume and PM2.5 levels.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97c10295"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generate Confusion Matrix Heatmap for Classification Model\n",
        "if model_tuned_classification is not None and X_test_classification is not None and y_test_classification is not None:\n",
        "    y_pred_classification = model_tuned_classification.predict(X_test_classification)\n",
        "    cm = confusion_matrix(y_test_classification, y_pred_classification)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['High', 'Low', 'Medium'], yticklabels=['High', 'Low', 'Medium']) # Assuming labels based on previous output\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix for Traffic Volume Classification')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Classification model or test data not available for confusion matrix heatmap.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbIWCsBscOJWuKjar1Ru/E",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}